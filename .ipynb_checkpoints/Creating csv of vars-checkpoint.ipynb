{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a23dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def income_pyramids_create_vars(filename,path):\n",
    "    \n",
    "    #  filename: Name of the file you want to create. eg:- \"parikshit.csv\"\n",
    "    #  path: Location of the file. location + name.csv\n",
    "    #  Eg:- path = r'C:\\Documents\\Data sets\\Income Pyramids-20211206T143645Z-001\\aspirational_india_20180901_20181231_R.csv'\n",
    "    \n",
    "    \n",
    "    varlist = \"HH_ID\tMEM_ID\tSTATE\tHR\tDISTRICT\tREGION_TYPE\tSTRATUM\tPSU_ID\tMONTH_SLOT\tRESPONSE_STATUS\tREASON_FOR_NON_RESPONSE\tFAMILY_SHIFTED\tMEM_WEIGHT_W\tMEM_WEIGHT_FOR_COUNTRY_W\tMEM_WEIGHT_FOR_STATE_W\tGE15_MEM_WEIGHT_W\tGE15_MEM_WEIGHT_FOR_COUNTRY_W\tGE15_MEM_WEIGHT_FOR_STATE_W\tMEM_NON_RESPONSE_W\tMEM_NON_RESPONSE_FOR_COUNTRY_W\tMEM_NON_RESPONSE_FOR_STATE_W\tGE15_MEM_NON_RESPONSE_W\tGE15_MEM_NON_RESPONSE_FOR_COUNTRY_W\tGE15_MEM_NON_RESPONSE_FOR_STATE_W\tMEMBER_STATUS\tREASON_FOR_EMIGRATION_IMMIGRATION\tEMIGRATED_IMMIGRATED_FROM_TO_STATE\tEMIGRATED_IMMIGRATED_FROM_TO_DISTRICT\tEMIGRATED_IMMIGRATED_FROM_TO_REGION_TYPE\tWILL_EMIGRATE\tWILL_EMIGRATE_REASON\tTIME_TO_EMIGRATE\tWILL_EMIGRATE_STATE\tWILL_EMIGRATE_DISTRICT\tWILL_EMIGRATE_REGION_TYPE\tEMPLOYMENT_STATUS\tEMPLOYMENT_STATUS_SINCE_YRS\tEMPLOYMENT_STATUS_SINCE_MTHS\tEMPLOYMENT_STATUS_SINCE_DAYS\tTYPE_OF_EMPLOYMENT\tEMPLOYMENT_ARRANGEMENT\tTIME_TO_START_WORKING\tTIME_SPENT_ON_WORK_FOR_HH_AND_MEM\tTIME_SPENT_ON_WORK_FOR_EMPLOYER\tTIME_SPENT_ON_WORK_AS_UNPAID_TRAINEE\tTIME_SPENT_ON_WORK_AS_UNPAID_VOLUNTEER\tTIME_SPENT_ON_TRAVEL\tTIME_SPENT_ON_LEARNING\tTIME_SPENT_ON_RELIGIOUS_ACTIVITIES\tTIME_SPENT_ON_OUTDOOR_SPORTS\tTIME_SPENT_ON_HANGING_OUT_OR_WITH_FRIENDS\tTIME_SPENT_ON_INDOOR_ENTERTAINMENT\tTIME_SPENT_ON_OTHER_ACTIVITIES_FOR_SELF\"\n",
    "    cols = varlist.split()\n",
    "    path = path\n",
    "    df = pd.read_csv(path)\n",
    "    df_cols = list(df.columns)\n",
    "    vars_not_found = []\n",
    "    for col in cols:\n",
    "        if col not in df_cols:\n",
    "            print(str(col) + \" not found in the dataset\")\n",
    "            vars_not_found.append(col)\n",
    "    cols_available = set(list(cols)) - set(vars_not_found)\n",
    "    df_new = df[cols_available]\n",
    "    df_new.to_csv(filename)\n",
    "    \n",
    "def consumer_pyramids_create_vars(filename,path):\n",
    "    \n",
    "    #  filename: Name of the file you want to create. eg:- \"parikshit.csv\"\n",
    "    #  path: Location of the file. Eg:- r'C:\\Users\\parik\\Documents\\Data sets\\Income Pyramids-20211206T143645Z-001\\Income Pyramids\\Member Incomes\\member_income_20210531_MS_csv\\aspirational_india_20180901_20181231_R.cs'\n",
    "\n",
    "    ### path = location + name.csv\n",
    "    \n",
    "   \n",
    "    \n",
    "    varlist = \"HH_ID\tSTATE\tHR\tDISTRICT\tREGION_TYPE\tSTRATUM\tPSU_ID\tMONTH_SLOT\tMONTH\tRESPONSE_STATUS\tREASON_FOR_NON_RESPONSE\tFAMILY_SHIFTED\tHH_WEIGHT_W\tHH_WEIGHT_FOR_COUNTRY_W\tHH_WEIGHT_FOR_STATE_W\tHH_WEIGHT_MS\tHH_WEIGHT_FOR_COUNTRY_MS\tHH_WEIGHT_FOR_STATE_MS\tHH_NON_RESPONSE_W\tHH_NON_RESPONSE_FOR_COUNTRY_W\tHH_NON_RESPONSE_FOR_STATE_W\tHH_NON_RESPONSE_MS\tHH_NON_RESPONSE_FOR_COUNTRY_MS\tHH_NON_RESPONSE_FOR_STATE_MS\tTOTAL_EXPENDITURE\tADJ_TOTAL_EXPENDITURE\tMONTHLY_EXPENSE_ON_FOOD\tADJ_MONTHLY_EXPENSE_ON_FOOD\tMONTHLY_EXPENSE_ON_INTERNET\tMONTHLY_EXPENSE_ON_EDUCATION\tMONTHLY_EXPENSE_ON_BOOKS_JOURNALS\tMONTHLY_EXPENSE_ON_SCHOOL_ACADEMIC_BOOKS\tMONTHLY_EXPENSE_ON_SCHOOL_COLLEGE_FEES\tMONTHLY_EXPENSE_ON_PRIVATE_TUITION_FEES\tMONTHLY_EXPENSE_ON_ADDITIONAL_PROFESSIONAL_EDUCATION\tMONTHLY_EXPENSE_ON_OVERSEAS_EDUCATION\tMONTHLY_EXPENSE_ON_OTHERS_EDUCATION\tMONTHLY_EXPENSE_ON_HEALTH\tMONTHLY_EXPENSE_ON_MEDICINES\tMONTHLY_EXPENSE_ON_EMI_FOR_HOUSE\tMONTHLY_EXPENSE_ON_EMI_FOR_VEHICLES\tMONTHLY_EXPENSE_ON_EMI_FOR_DURABLES\tMONTHLY_EXPENSE_ON_POCKET_MONEY\t\t\t\t\t\t\t\t\t\t\"\n",
    "    cols = varlist.split()\n",
    "    path = path\n",
    "    df = pd.read_csv(path)\n",
    "    df_cols = list(df.columns)\n",
    "    vars_not_found = []\n",
    "    for col in cols:\n",
    "        if col not in df_cols:\n",
    "            print(str(col) + \" not found in the dataset\")\n",
    "            vars_not_found.append(col)\n",
    "    cols_available = set(list(cols)) - set(vars_not_found)\n",
    "    df_new = df[cols_available]\n",
    "    df_new.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "da70d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# income_pyramids_create_vars(\"parikshit.csv\", r\"C:\\Users\\parik\\Documents\\Data sets\\aspirations\\drive-download-20220221T055656Z-001\\aspirational_india_20180901_20181231_R_csv\\aspirational_india_20180901_20181231_R.csv\")\n",
    "# consumer_pyramids_create_vars(\"parikshit.csv\", r\"C:\\Users\\parik\\Documents\\Data sets\\aspirations\\drive-download-20220221T055656Z-001\\aspirational_india_20180901_20181231_R_csv\\aspirational_india_20180901_20181231_R.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f85b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
